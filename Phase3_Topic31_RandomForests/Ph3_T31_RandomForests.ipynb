{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div style=\"color:white;\n",
    "           display:fill;\n",
    "           border-radius:5px;\n",
    "           background-color:#5642C5;\n",
    "           font-size:200%;\n",
    "           font-family:Arial;letter-spacing:0.5px\">\n",
    "\n",
    "<p width = 20%, style=\"padding: 10px;\n",
    "              color:white;\">\n",
    "Ensemble Learning: Bagging and Random Forests\n",
    "              \n",
    "</p>\n",
    "</div>\n",
    "\n",
    "Data Science Cohort Live NYC Feb 2022\n",
    "<p>Phase 3: Topic 31</p>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<div align = \"right\">\n",
    "<img src=\"Images/flatiron-school-logo.png\" align = \"right\" width=\"200\"/>\n",
    "</div>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,\\\n",
    "cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier,\\\n",
    "ExtraTreesClassifier, VotingClassifier, StackingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Motivation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Kim-Jong-un after using decision tree: launch nukes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/kimjongun.jpg\" width = 700 /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Maybe better to make this a more democratic process with more perspectives on the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Other decision makers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<table><tr><td><img src=\"Images/mother_teresa.webp\" width=\"250\"/><br><center>Mother Theresa</center></td><td><img src=\"Images/sakharov.jpg\" width=\"200\"/><br><center>Andrei Sakharov</center></td><td><img src=\"Images/cat_press_button.gif\" width=\"300\"/><br><center>Nice kitty.</center></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This thinking applicable to all models:\n",
    "- particularly useful in the context of Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Deficiencies of Decision Trees:\n",
    "- that ensemble learning can address."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Reminder of decision trees: \n",
    "- recursively make splits based on entropy or impurity\n",
    "- split on feature best increasing information gain\n",
    "- Keep splitting until leaf pure OR max depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/dec_tree_partitioning.jpg\" width = 800/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Tendency to overfit at large max depth.\n",
    "- High enough depth: will fit to training set perfectly.\n",
    "\n",
    "<img src = \"Images/dectree_perfectfit.png\" />\n",
    "<center> A perfect fit to the training set. </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/decisiontree_classification_overfitting.png\"  />\n",
    "<center> Some more decision tree overfitting </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Too much **variance**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To avoid: reduce decision tree depth to limit variance.\n",
    "    \n",
    "But with decision tree, will easily end up underfitting.\n",
    "\n",
    "- Can increase depth again to get better:\n",
    "    - But very likely to learn a boundary that overfits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/dectree_underfitting.png\" width = 400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Bias-variance problem is severe with Decision Tree models:\n",
    "- Very sensitive to tree depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A very nice visualization of this sensitivity on the regression task:\n",
    "<img src = \"Images/decision_tree_regression.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Decision trees not-robust**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Criterion is harsh: choose *single* feature that wins and split on that.\n",
    "- But many features may be important in a region and should be factored in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src = \"Images/tree_features.png\" />\n",
    "Both Culmen length and depth matter here. But split for each region considers only one or the other.\n",
    "\n",
    "- Doesn't reflect the way features are related to each other and collectively impact the target.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Can we figure out a way in a split for a given subregion to factor in different features?**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Depending on goal could be nice if modeling target-feature function:\n",
    "- without feature engineering.\n",
    "- without distributional assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Another issue:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Recursion: after split on \"best\" feature, different subsets never talk to each other again.\n",
    "- But maybe other branches/regions: info influencing split/class assignment in given subregion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/dec_tree_partitioning.jpg\" width =800/>\n",
    "<center>Choosing next split in green region: black or green?</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Perhaps sampling/factoring in different regions and features?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Increasing depth and number of splits:\n",
    "- Very quickly: small number of points in given sub-region\n",
    "- Feature decision very sensitive to points in specific region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points.png\" width = 200 />\n",
    "<center> Plausible small subregion with few points </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Two possible choices (equivalent in terms of impurity):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt1.png\" width = 200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt2.png\" width = 200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Decision boundary instability: \n",
    "- small changes/fluctuations in data lead to very different decision surface locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt1_inst.png\" width =400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/data_points_splt2_inst.png\" width =400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How to get around this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Don't want to rely too heavily on specific data points and their location:\n",
    "- Maybe introducing randomness in data point sampling in some way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Why am I using decision trees at all then?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### But decision trees are blindingly fast.\n",
    "- Recursion on binary trees\n",
    "- Greedy criterion:\n",
    "    - always split on best feature at local node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Want to keep this speed and still use trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But also want to:\n",
    "- Sample other features when making splits\n",
    "- Sample other regions in feature-space when making decisions on class assignments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Learn from classifiers training on different realizations of the dataset:\n",
    "    - a set of given points has different weight/importance in each realization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Way to create realization of dataset with different weights for data: \n",
    "- **Bagging (boostrap aggregation)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/sample_bagging_only.png\" width = 800/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src = \"Images/sample_bagging_only.png\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The bootstrap:\n",
    "\n",
    "- N samples in training set.\n",
    "- Randomly resample training set **with replacement** N times.\n",
    "- Resampled set also has N samples.\n",
    "\n",
    "A given point now has different weight/importance in each realization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "More explicitly: see training point reweighting under bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  1. ],\n",
       "       [ 3.1,  0. ],\n",
       "       [-2.5,  1. ],\n",
       "       [ 1. ,  0. ],\n",
       "       [-4. ,  1. ],\n",
       "       [ 0.5,  0. ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (feature, label) pairs\n",
    "train = np.array([(-1,1), (3.1, 0) , (-2.5, 1),\n",
    "         (1, 0), (-4, 1), (.5, 0)])\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1. ,  1. ],\n",
       "       [-2.5,  1. ],\n",
       "       [-4. ,  1. ],\n",
       "       [-1. ,  1. ],\n",
       "       [ 3.1,  0. ],\n",
       "       [ 1. ,  0. ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import choice\n",
    "idx_resampled = choice(range(len(train)), \n",
    "                      size = len(train),\n",
    "                       replace = True)\n",
    "train[idx_resampled]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Now use ensemble of trained models\n",
    "- Aggregate to make prediction on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/bagging_classifier.png\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the context of regression:\n",
    "- aggregation function is average of regressor trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src = \"Images/bagging_regressor.png\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The concept of bagging of estimators is **NOT** limited to trees:\n",
    "- can use any classifier or regressor and perform bagging procedures.\n",
    "- but mainly useful for local models like DecisionTree or KNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To implement bagging classifier in sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# if doing classification\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# if doing regression\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We'll do classification:\n",
    "- Predict diabetes via health stats\n",
    "- Pima Indian diabetes dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab_df = pd.read_csv('Data/diabetes.csv')\n",
    "diab_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "diab_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Separate features and target\n",
    "- Train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "X = diab_df.drop(columns = ['Outcome'])\n",
    "y = diab_df['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size = 0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now develop our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Define the bagging classifier and put it into a pipeline. \n",
    "\n",
    "Then integrate into a grid search tuning on tree depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bag_class_decision = BaggingClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 150)\n",
    "bag_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                      ('model',\n",
    "                       bag_class_decision)])\n",
    "params = {'model__base_estimator__max_depth': np.arange(4,28,4)}\n",
    "cv = GridSearchCV(estimator = bag_pipe, param_grid = params, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cv.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Get best model and its balanced accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__base_estimator__max_depth': 20}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = cv.best_estimator_\n",
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792248972401644"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__base_estimator__max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.768514</td>\n",
       "      <td>0.033288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.777722</td>\n",
       "      <td>0.031320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0.774680</td>\n",
       "      <td>0.038101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.774668</td>\n",
       "      <td>0.035615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.779225</td>\n",
       "      <td>0.029758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24</td>\n",
       "      <td>0.770029</td>\n",
       "      <td>0.029922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_model__base_estimator__max_depth  mean_test_score  std_test_score\n",
       "0                                      4         0.768514        0.033288\n",
       "1                                      8         0.777722        0.031320\n",
       "2                                     12         0.774680        0.038101\n",
       "3                                     16         0.774668        0.035615\n",
       "4                                     20         0.779225        0.029758\n",
       "5                                     24         0.770029        0.029922"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv.cv_results_)[['param_model__base_estimator__max_depth', 'mean_test_score', 'std_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Fit the best model. Get predictions and report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "best_model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79        76\n",
      "           1       0.61      0.57      0.59        40\n",
      "\n",
      "    accuracy                           0.72       116\n",
      "   macro avg       0.69      0.69      0.69       116\n",
      "weighted avg       0.72      0.72      0.72       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Is bagging better than baseline decision tree over the same range of tree depths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "simpletree_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                      ('model',\n",
    "                       DecisionTreeClassifier())]) \n",
    "\n",
    "params = {'model__max_depth': np.arange(4,28,4)}\n",
    "\n",
    "cvtree = GridSearchCV(estimator = simpletree_pipe, param_grid = params, cv = 5)\n",
    "\n",
    "cvtree.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__max_depth': 4}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_simplemodel = cvtree.best_estimator_\n",
    "cvtree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.739271873165003"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvtree.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77        76\n",
      "           1       0.57      0.65      0.60        40\n",
      "\n",
      "    accuracy                           0.71       116\n",
      "   macro avg       0.68      0.69      0.69       116\n",
      "weighted avg       0.72      0.71      0.71       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_simplemodel.fit(X_train, y_train)\n",
    "y_pred_simple = best_simplemodel.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_simple))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Baggiing a bit better on the precision/recall for all classes -- especially positive class. \n",
    "- In many cases improvements on bagging alone will not be so significant.\n",
    "- Sample bagging alone usually not enough to capture feature space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Reason: \n",
    "- boostrapped samples are still highly correlated with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Final ingredient (first set of strategies)\n",
    "\n",
    "- Effectively factor in other features when making splits\n",
    "- Sample other regions in feature-space when making decisions on class assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Can effectively do this by considering only a random subset of features to split on at each node\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Result: each tree may partition feature space in appreciably different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src = \"Images/rf_splitting.png\"  width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Overall effect of this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/indtree.gif\"  width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Each decision tree can learn different important features to make splits on throughout feature space.\n",
    "- Each tree can assign a given feature region to different classes based on its splits factoring in different features.\n",
    "\n",
    "Individual trees making errors but **different** errors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src = \"Images/rfplot.gif\"  width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Aggregating smooths large fluctuations of class assignments from individual trees out.\n",
    "- Due to feature subset sampling: can learn more complex boundaries: smoothens these.\n",
    "- Can also get probability of class assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's try out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                      ('model',\n",
    "                       RandomForestClassifier(n_estimators = 100))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rf_pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y_rf_pred = rf_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81        76\n",
      "           1       0.64      0.57      0.61        40\n",
      "\n",
      "    accuracy                           0.74       116\n",
      "   macro avg       0.71      0.70      0.71       116\n",
      "weighted avg       0.74      0.74      0.74       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Better than bagging and base Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Should tune model: understand relevant hyperparameters\n",
    "- understand parameters of model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- n_estimators: number of trees in forest (very important):\n",
    "    - optimal will depend on dataset size. But 50-250 is good starting tuning range.\n",
    "- max_features: number of features to randomly sample at each node for evaluating split criterion.\n",
    "    - good starting value (also default) is $\\sqrt{M}$ where $M$ is number of features. (theoretical justification for this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- max_depth: tree depth\n",
    "    - due to randomizing and averaging: random forest not as sensitive to this as DecisionTree.\n",
    "    - default is None. Trains tree to leaf purity. Typically don't touch this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- min_sample_leaf: minimum number of samples required to be at a leaf node.\n",
    "    - Default is 1 but having larger numbers can mean averaging effect from leaf\n",
    "    - Higher values can have a regularizing effect.\n",
    "    - Typically tune from 1-100 (depends on size of data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For min sample leaf criterion: cuts out different portions of tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src = \"Images/min_sample_leaf.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Can also change objective functions:\n",
    "- Gini\n",
    "- entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Grid Search CV on our random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('model', RandomForestClassifier())]),\n",
       "             param_grid={'model__min_samples_leaf': [1, 3, 5, 7],\n",
       "                         'model__n_estimators': [50, 100, 200, 500]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {'model__n_estimators': [50, 100, 200, 500] ,\n",
    "             'model__min_samples_leaf': [1,3,5,7]}\n",
    "rf_cv = GridSearchCV(estimator = rf_pipe, param_grid = rf_params, cv = 5)\n",
    "rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7807398708162067"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__min_samples_leaf': 7, 'model__n_estimators': 200}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(min_samples_leaf=7, n_estimators=200))])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model = rf_cv.best_estimator_\n",
    "best_rf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('model',\n",
       "                 RandomForestClassifier(min_samples_leaf=7, n_estimators=200))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.83      0.81        76\n",
      "           1       0.64      0.57      0.61        40\n",
      "\n",
      "    accuracy                           0.74       116\n",
      "   macro avg       0.71      0.70      0.71       116\n",
      "weighted avg       0.74      0.74      0.74       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_rfcv_pred = best_rf_model.predict(X_test)\n",
    "print(classification_report(y_test,y_rfcv_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "OK this is pretty decent. There is also another nice thing about random forests:\n",
    "\n",
    "Can see which features are most important in prediction:\n",
    "\n",
    "- .feature_importances_ attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "feat_imp = best_rf_model['model'].feature_importances_\n",
    "\n",
    "feat_imp_series = pd.Series(feat_imp, \n",
    "          index = X.columns).sort_values(\n",
    "    ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Glucose                     0.347525\n",
       "BMI                         0.170861\n",
       "Age                         0.156212\n",
       "DiabetesPedigreeFunction    0.083030\n",
       "Pregnancies                 0.066654\n",
       "Insulin                     0.063818\n",
       "BloodPressure               0.056657\n",
       "SkinThickness               0.055244\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp_series.plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Evaluates feature importance:\n",
    "- Determining for each tree how many times feature was used for splitting.\n",
    "- Counts up occurences across entire forest and weights features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Extremely Randomized Trees (Extra Trees)\n",
    "- Sometimes our variance problems are extreme.\n",
    "- Random forest taking way too long with too many estimators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Might want even one more randomization. \n",
    "- Instead of always choosing the *optimal* split at node:\n",
    "    - randomly sample feature space inside node. \n",
    "    - split on best information gain from random sample.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now **three** levels of randomization: \n",
    "- sampling of data\n",
    "- sampling of features\n",
    "- random selection of branching paths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Compare typical effects:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src = \"Images/extraatrees_forest_iris.png\" width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Extra randomness makes ExtraTrees a softer classifier.\n",
    "- Very good for variance issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's import it and do our magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate an ExtraTreesClassifier\n",
    "\n",
    "etc = ExtraTreesClassifier(max_features='sqrt',\n",
    "                         max_samples=0.5,\n",
    "                         bootstrap=True,\n",
    "                         random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=True, max_features='sqrt', max_samples=0.5,\n",
       "                     random_state=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit it\n",
    "\n",
    "etc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77862595, 0.74045802, 0.76153846, 0.75384615, 0.76153846])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-validation\n",
    "\n",
    "scores = cross_val_score(estimator=etc, X=X_train,\n",
    "               y=y_train, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7615384615384615"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "cell_style": "split",
    "hidden": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7241379310344828"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Score on test\n",
    "\n",
    "etc.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80        76\n",
      "           1       0.62      0.50      0.56        40\n",
      "\n",
      "    accuracy                           0.72       116\n",
      "   macro avg       0.69      0.67      0.68       116\n",
      "weighted avg       0.71      0.72      0.72       116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_etc_pred = etc.predict(X_test)\n",
    "print(classification_report(y_test, y_etc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Sometimes** the extra randomization can do even better.\n",
    "- When suffering from variance issues.\n",
    "- Also ExtraTrees is very very fast:\n",
    "    - doesn't spend too much time on finding optimal splits."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "TOC",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
